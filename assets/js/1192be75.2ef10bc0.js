"use strict";(self.webpackChunkai_maniacs=self.webpackChunkai_maniacs||[]).push([[3391],{513:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"ai-101/foundations/context-window","title":"What is the Context Window?","description":"Learn about context windows in LLMs - how much information AI models can remember and work with in a single conversation","source":"@site/docs/ai-101/foundations/context-window.md","sourceDirName":"ai-101/foundations","slug":"/ai-101/foundations/context-window","permalink":"/docs/ai-101/foundations/context-window","draft":false,"unlisted":false,"editUrl":"https://github.com/sethdavis512/ai-maniacs/tree/main/docs/ai-101/foundations/context-window.md","tags":[],"version":"current","lastUpdatedBy":"Seth Davis","lastUpdatedAt":1756236131000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"What is the Context Window?","description":"Learn about context windows in LLMs - how much information AI models can remember and work with in a single conversation","keywords":["context window","LLM","memory","conversation","AI limitations","token limit"],"image":"/img/ai-maniacs-social-card.jpg"},"sidebar":"ai101Sidebar","previous":{"title":"Understanding Large Language Models (LLMs)","permalink":"/docs/ai-101/foundations/understanding-llms"},"next":{"title":"Types of AI Models","permalink":"/docs/ai-101/foundations/types-of-ai-models"}}');var o=t(4848),s=t(8453);const r={sidebar_position:3,title:"What is the Context Window?",description:"Learn about context windows in LLMs - how much information AI models can remember and work with in a single conversation",keywords:["context window","LLM","memory","conversation","AI limitations","token limit"],image:"/img/ai-maniacs-social-card.jpg"},a="What is the Context Window?",l={},d=[{value:"Learning Focus",id:"learning-focus",level:2},{value:"What is a Context Window?",id:"what-is-a-context-window",level:2},{value:"A Simple Analogy",id:"a-simple-analogy",level:3},{value:"How Context Windows Work",id:"how-context-windows-work",level:2},{value:"Tokens, Not Words",id:"tokens-not-words",level:3},{value:"Different Models, Different Sizes",id:"different-models-different-sizes",level:3},{value:"What Counts Toward the Context Window",id:"what-counts-toward-the-context-window",level:3},{value:"Why Context Windows Matter",id:"why-context-windows-matter",level:2},{value:"Memory Limitations",id:"memory-limitations",level:3},{value:"Performance Impact",id:"performance-impact",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Writing Project",id:"example-1-writing-project",level:3},{value:"Example 2: Long Conversation",id:"example-2-long-conversation",level:3},{value:"Example 3: Document Analysis",id:"example-3-document-analysis",level:3},{value:"Working Effectively Within Context Windows",id:"working-effectively-within-context-windows",level:2},{value:"Strategy 1: Be Concise",id:"strategy-1-be-concise",level:3},{value:"Strategy 2: Summarize Long Conversations",id:"strategy-2-summarize-long-conversations",level:3},{value:"Strategy 3: Break Large Tasks into Smaller Parts",id:"strategy-3-break-large-tasks-into-smaller-parts",level:3},{value:"Strategy 4: Use External Memory",id:"strategy-4-use-external-memory",level:3},{value:"Context Window Limitations to Remember",id:"context-window-limitations-to-remember",level:2},{value:"Information Loss",id:"information-loss",level:3},{value:"No Permanent Learning",id:"no-permanent-learning",level:3},{value:"Processing Order",id:"processing-order",level:3},{value:"When Context Window Size Matters Most",id:"when-context-window-size-matters-most",level:2},{value:"Large Context Windows Are Important For:",id:"large-context-windows-are-important-for",level:3},{value:"Small Context Windows Are Sufficient For:",id:"small-context-windows-are-sufficient-for",level:3},{value:"Future of Context Windows",id:"future-of-context-windows",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"what-is-the-context-window",children:"What is the Context Window?"})}),"\n",(0,o.jsxs)(n.p,{children:['When you have a conversation with an AI like ChatGPT or Claude, have you ever noticed that it seems to "forget" things you mentioned earlier in a long chat? This happens because of something called the ',(0,o.jsx)(n.strong,{children:"context window"})," - one of the most important concepts to understand when working with AI."]}),"\n",(0,o.jsx)(n.h2,{id:"learning-focus",children:"Learning Focus"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this lesson, you'll understand:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"What a context window is and why it exists"}),"\n",(0,o.jsx)(n.li,{children:"How context windows affect your AI conversations"}),"\n",(0,o.jsx)(n.li,{children:"How to work effectively within these limitations"}),"\n",(0,o.jsx)(n.li,{children:"When context window size matters for different tasks"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"what-is-a-context-window",children:"What is a Context Window?"}),"\n",(0,o.jsxs)(n.p,{children:["A ",(0,o.jsx)(n.strong,{children:"context window"}),' is the maximum amount of information an AI model can "remember" and work with at one time. Think of it like the AI\'s short-term memory - it can only hold a certain amount of information before it starts forgetting earlier parts of the conversation.']}),"\n",(0,o.jsx)(n.h3,{id:"a-simple-analogy",children:"A Simple Analogy"}),"\n",(0,o.jsx)(n.p,{children:"Imagine you're having a conversation with someone who can only remember the last 10 sentences spoken. Once you reach the 11th sentence, they forget the first one completely. That's essentially how a context window works."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Example conversation:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:'You: "My name is Sarah, and I love hiking."\nAI: "Nice to meet you, Sarah! Hiking is a great hobby."\n\n[... many exchanges later ...]\n\nYou: "What\'s my name and hobby?"\nAI: "I\'m sorry, but I don\'t see that information in our conversation."\n'})}),"\n",(0,o.jsx)(n.p,{children:'The AI "forgot" because that information fell outside its context window.'}),"\n",(0,o.jsx)(n.h2,{id:"how-context-windows-work",children:"How Context Windows Work"}),"\n",(0,o.jsx)(n.h3,{id:"tokens-not-words",children:"Tokens, Not Words"}),"\n",(0,o.jsxs)(n.p,{children:["Context windows are measured in ",(0,o.jsx)(n.strong,{children:"tokens"}),", not words. A token can be:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'A whole word ("hello")'}),"\n",(0,o.jsx)(n.li,{children:'Part of a word ("ing" in "running")'}),"\n",(0,o.jsx)(n.li,{children:"A single character or punctuation mark"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Rough conversion:"})," 1 word \u2248 1.3 tokens on average"]}),"\n",(0,o.jsx)(n.h3,{id:"different-models-different-sizes",children:"Different Models, Different Sizes"}),"\n",(0,o.jsx)(n.p,{children:"Each AI model has a different context window size:"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Common Context Window Sizes (as of 2024):"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"GPT-3.5: ~4,000 tokens (~3,000 words)"}),"\n",(0,o.jsx)(n.li,{children:"GPT-4: ~8,000-128,000 tokens (~6,000-96,000 words)"}),"\n",(0,o.jsx)(n.li,{children:"Claude 3: ~200,000 tokens (~150,000 words)"}),"\n",(0,o.jsx)(n.li,{children:"Gemini Pro: ~32,000 tokens (~24,000 words)"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"what-counts-toward-the-context-window",children:"What Counts Toward the Context Window"}),"\n",(0,o.jsx)(n.p,{children:"Everything in your conversation counts toward the context window:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Your messages to the AI"}),"\n",(0,o.jsx)(n.li,{children:"The AI's responses back to you"}),"\n",(0,o.jsx)(n.li,{children:"System instructions (hidden prompts that guide the AI's behavior)"}),"\n",(0,o.jsx)(n.li,{children:"Any files or documents you share"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"why-context-windows-matter",children:"Why Context Windows Matter"}),"\n",(0,o.jsx)(n.h3,{id:"memory-limitations",children:"Memory Limitations"}),"\n",(0,o.jsx)(n.p,{children:'When the context window fills up, the AI starts "forgetting" the oldest information. This affects:'}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Long conversations:"})," The AI may forget your preferences or earlier requests"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Document analysis:"})," Large documents may not fit entirely in the context window"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Complex projects:"})," Multi-step tasks may lose important details"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-impact",children:"Performance Impact"}),"\n",(0,o.jsx)(n.p,{children:"Larger context windows aren't always better:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cost:"})," More tokens often mean higher usage costs"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Speed:"})," Processing larger contexts takes more time"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Accuracy:"})," Very long contexts can sometimes confuse the AI"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,o.jsx)(n.h3,{id:"example-1-writing-project",children:"Example 1: Writing Project"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"Context Window: 4,000 tokens\n\nYour request: \"Help me write a 5,000-word research paper on climate change\"\n\nProblem: The entire paper won't fit in the context window, so the AI \ncan't maintain consistency throughout the whole document.\n\nBetter approach: Break it into sections and work on each piece separately.\n"})}),"\n",(0,o.jsx)(n.h3,{id:"example-2-long-conversation",children:"Example 2: Long Conversation"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"Hour 1: You discuss your marketing strategy\nHour 2: You ask about budget planning  \nHour 3: You return to marketing questions\n\nProblem: The AI may have forgotten the marketing details from Hour 1.\n\nBetter approach: Summarize key points when returning to earlier topics.\n"})}),"\n",(0,o.jsx)(n.h3,{id:"example-3-document-analysis",children:"Example 3: Document Analysis"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"Your task: Analyze a 50-page legal contract\nContext Window: 32,000 tokens (~24,000 words)\nContract length: ~35,000 words\n\nProblem: The entire contract won't fit at once.\n\nBetter approach: Analyze the contract in sections, then combine insights.\n"})}),"\n",(0,o.jsx)(n.h2,{id:"working-effectively-within-context-windows",children:"Working Effectively Within Context Windows"}),"\n",(0,o.jsx)(n.h3,{id:"strategy-1-be-concise",children:"Strategy 1: Be Concise"}),"\n",(0,o.jsx)(n.p,{children:"Remove unnecessary details from your prompts:"}),"\n",(0,o.jsxs)(n.p,{children:["\u274c ",(0,o.jsx)(n.strong,{children:"Poor approach:"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"\"So I was thinking about this project I'm working on, and it's really important \nto me, and I want to make sure I do a good job because my boss will be reviewing \nit, and I'm wondering if you could help me write an email to the client about \nthe delay we're experiencing...\"\n"})}),"\n",(0,o.jsxs)(n.p,{children:["\u2705 ",(0,o.jsx)(n.strong,{children:"Better approach:"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:'"Help me write a professional email to a client explaining a project delay."\n'})}),"\n",(0,o.jsx)(n.h3,{id:"strategy-2-summarize-long-conversations",children:"Strategy 2: Summarize Long Conversations"}),"\n",(0,o.jsx)(n.p,{children:"When approaching the context limit, create a summary:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"\"Before we continue, here's a summary of our discussion:\n- Goal: Create a marketing campaign for Product X\n- Target audience: Young professionals aged 25-35  \n- Budget: $50,000\n- Timeline: 3 months\n- Preferred channels: Social media and email\n\nNow, let's discuss the creative strategy...\"\n"})}),"\n",(0,o.jsx)(n.h3,{id:"strategy-3-break-large-tasks-into-smaller-parts",children:"Strategy 3: Break Large Tasks into Smaller Parts"}),"\n",(0,o.jsx)(n.p,{children:"Instead of processing everything at once:"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Large task:"}),' "Analyze this 100-page report and create a presentation"']}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Broken down:"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Analyze pages 1-25 and identify key themes"}),"\n",(0,o.jsx)(n.li,{children:"Analyze pages 26-50 and extract important data"}),"\n",(0,o.jsx)(n.li,{children:"Analyze pages 51-75 and note recommendations"}),"\n",(0,o.jsx)(n.li,{children:"Analyze pages 76-100 and summarize conclusions"}),"\n",(0,o.jsx)(n.li,{children:"Create presentation outline based on all findings"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"strategy-4-use-external-memory",children:"Strategy 4: Use External Memory"}),"\n",(0,o.jsx)(n.p,{children:"Save important information outside the conversation:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Keep notes in a separate document"}),"\n",(0,o.jsx)(n.li,{children:"Save key decisions and preferences"}),"\n",(0,o.jsx)(n.li,{children:"Create templates for repeated requests"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"context-window-limitations-to-remember",children:"Context Window Limitations to Remember"}),"\n",(0,o.jsx)(n.h3,{id:"information-loss",children:"Information Loss"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"The AI doesn't choose what to forget - it loses the oldest information first"}),"\n",(0,o.jsx)(n.li,{children:"Important details from early in the conversation may disappear"}),"\n",(0,o.jsx)(n.li,{children:"The AI can't warn you when it's approaching the context limit"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"no-permanent-learning",children:"No Permanent Learning"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Most AI models don't learn from individual conversations"}),"\n",(0,o.jsx)(n.li,{children:"Each new chat session starts fresh"}),"\n",(0,o.jsx)(n.li,{children:"Context windows reset between separate conversations"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"processing-order",children:"Processing Order"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"The AI processes information sequentially"}),"\n",(0,o.jsx)(n.li,{children:"Information at the end of the context window may have more influence"}),"\n",(0,o.jsx)(n.li,{children:"Very long contexts can sometimes lead to inconsistent responses"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"when-context-window-size-matters-most",children:"When Context Window Size Matters Most"}),"\n",(0,o.jsx)(n.h3,{id:"large-context-windows-are-important-for",children:"Large Context Windows Are Important For:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Document analysis:"})," Working with long reports, contracts, or research papers"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Code reviews:"})," Analyzing large codebases or multiple files"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Creative projects:"})," Maintaining consistency in long-form writing"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Research tasks:"})," Processing multiple sources simultaneously"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"small-context-windows-are-sufficient-for",children:"Small Context Windows Are Sufficient For:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simple questions:"})," Quick facts or explanations"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Short tasks:"})," Brief emails or social media posts"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Focused conversations:"})," Discussing one topic at a time"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Learning:"})," Understanding individual concepts"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"future-of-context-windows",children:"Future of Context Windows"}),"\n",(0,o.jsx)(n.p,{children:"Context windows are rapidly expanding:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"2023:"})," Most models had 4,000-8,000 token limits"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"2024:"})," Leading models now support 200,000+ tokens"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Future:"})," Million-token context windows are being developed"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"However, larger context windows also bring new challenges:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Higher costs for processing"}),"\n",(0,o.jsx)(n.li,{children:"Potential for information overload"}),"\n",(0,o.jsx)(n.li,{children:"Need for better organization of long conversations"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Context windows determine how much information AI models can work with at once"}),"\n",(0,o.jsx)(n.li,{children:"Different models have vastly different context window sizes"}),"\n",(0,o.jsx)(n.li,{children:"When the window fills up, the oldest information gets forgotten"}),"\n",(0,o.jsx)(n.li,{children:"Work within context limits by being concise, summarizing, and breaking large tasks into parts"}),"\n",(0,o.jsx)(n.li,{children:"Larger context windows enable more complex tasks but aren't always necessary"}),"\n",(0,o.jsx)(n.li,{children:"Understanding context windows helps you communicate more effectively with AI"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"Now that you understand context windows, you're ready to explore the different types of AI models and their specific capabilities. Each model type has different context window characteristics that affect how you can use them."}),"\n",(0,o.jsxs)(n.p,{children:["Continue to: ",(0,o.jsx)(n.a,{href:"/docs/ai-101/foundations/types-of-ai-models",children:"Types of AI Models"})]}),"\n",(0,o.jsx)(n.admonition,{type:"warning",children:(0,o.jsx)(n.p,{children:"Content created with AI assistance - may contain errors or become outdated."})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var i=t(6540);const o={},s=i.createContext(o);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);